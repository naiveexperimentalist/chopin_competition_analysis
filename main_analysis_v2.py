"""
GÅ‚Ã³wny skrypt do kompleksowej analizy konkursu Chopinowskiego 2025
Integruje wszystkie moduÅ‚y i przeprowadza peÅ‚nÄ… analizÄ™
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime
import os
import sys

# Import moduÅ‚Ã³w podstawowych
from chopin_data_processor import ChopinCompetitionProcessor, process_competition_data
from chopin_advanced_analyzer import ChopinAdvancedAnalyzer, run_advanced_analysis
from chopin_visualization import ChopinVisualization

# Import nowych moduÅ‚Ã³w analitycznych
from chopin_controversy_analyzer import ChopinControversyAnalyzer, run_controversy_analysis
from chopin_statistical_analyzer import ChopinStatisticalAnalyzer, run_statistical_analysis
from chopin_clustering_analyzer import ChopinClusteringAnalyzer, run_clustering_analysis
from chopin_statistical_visualization import ChopinStatisticalVisualization
from chopin_advanced_visualizations import run_advanced_visualizations
from chopin_multistage_clustering import run_multistage_analysis


def create_analysis_report(processor, analyzer, visualizer, output_dir='full_analysis'):
    """
    Tworzy kompletny raport analizy konkursu
    POPRAWIONA WERSJA - zawiera wszystkie analizy
    """
    os.makedirs(output_dir, exist_ok=True)
    
    # OtwÃ³rz plik raportu
    report_path = f'{output_dir}/analysis_report.md'
    
    with open(report_path, 'w', encoding='utf-8') as f:
        f.write("# Raport Analizy Konkursu Chopinowskiego 2025\n\n")
        f.write(f"Data analizy: {datetime.now().strftime('%Y-%m-%d %H:%M')}\n\n")
        
        # 1. Podstawowe statystyki
        f.write("## 1. Podstawowe statystyki\n\n")
        
        # Liczba uczestnikÃ³w per etap
        f.write("### Liczba uczestnikÃ³w w poszczegÃ³lnych etapach:\n")
        for stage_name, df in processor.stages_data.items():
            f.write(f"- **{stage_name}**: {len(df)} uczestnikÃ³w\n")
        
        # 2. Analiza sÄ™dziÃ³w
        f.write("\n## 2. Analiza sÄ™dziÃ³w\n\n")
        
        judge_stats = analyzer.get_judge_statistics()
        if not judge_stats.empty:
            f.write("### Wykorzystanie skali przez sÄ™dziÃ³w:\n\n")
            scale_usage = analyzer.analyze_scale_usage()
            
            # Top 3 najbardziej liberalni w ocenach
            top_range = scale_usage.nlargest(3, 'overall_range')
            f.write("**SÄ™dziowie uÅ¼ywajÄ…cy najszerszej skali:**\n")
            for _, row in top_range.iterrows():
                f.write(f"- {row['judge']}: rozpiÄ™toÅ›Ä‡ {row['overall_range']:.1f} punktÃ³w\n")
            
            # Top 3 najbardziej konserwatywni
            bottom_range = scale_usage.nsmallest(3, 'overall_range')
            f.write("\n**SÄ™dziowie uÅ¼ywajÄ…cy najwÄ™Å¼szej skali:**\n")
            for _, row in bottom_range.iterrows():
                f.write(f"- {row['judge']}: rozpiÄ™toÅ›Ä‡ {row['overall_range']:.1f} punktÃ³w\n")
        
        # 3. Tendencje sÄ™dziowskie
        f.write("\n### Tendencje sÄ™dziowskie:\n\n")
        tendencies = analyzer.analyze_judge_tendencies()
        
        if not tendencies.empty:
            # Najbardziej surowi
            harsh = tendencies.nsmallest(3, 'overall_harshness')
            f.write("**Najbardziej surowi sÄ™dziowie:**\n")
            for _, row in harsh.iterrows():
                f.write(f"- {row['judge']}: Å›rednio {abs(row['overall_harshness']):.2f} punkta poniÅ¼ej konsensusu\n")
            
            # Najbardziej Å‚agodni
            lenient = tendencies.nlargest(3, 'overall_harshness')
            f.write("\n**Najbardziej Å‚agodni sÄ™dziowie:**\n")
            for _, row in lenient.iterrows():
                f.write(f"- {row['judge']}: Å›rednio {row['overall_harshness']:.2f} punkta powyÅ¼ej konsensusu\n")
        
        # 4. Sojusze sÄ™dziowskie
        f.write("\n## 3. Sojusze i korelacje\n\n")
        correlation_matrix, alliances = analyzer.analyze_judge_alliances(threshold=0.7)
        
        if not alliances.empty:
            f.write("### Najsilniejsze sojusze (korelacja > 0.7):\n")
            for _, row in alliances.head(5).iterrows():
                f.write(f"- **{row['judge1']}** i **{row['judge2']}**: korelacja {row['correlation']:.3f}\n")
        
        # 5. WpÅ‚yw usuniÄ™cia sÄ™dziego
        f.write("\n## 4. WpÅ‚yw pojedynczych sÄ™dziÃ³w na wyniki\n\n")
        removal_impact = analyzer.simulate_judge_removal()
        
        if not removal_impact.empty:
            most_influential = removal_impact.nlargest(3, 'avg_rank_change')
            f.write("### SÄ™dziowie o najwiÄ™kszym wpÅ‚ywie na ranking koÅ„cowy:\n")
            for _, row in most_influential.iterrows():
                f.write(f"- **{row['judge_removed']}**: usuniÄ™cie zmienia ranking Å›rednio o {row['avg_rank_change']:.2f} pozycji\n")
        
        # 5.1 NOWA SEKCJA - WpÅ‚yw na kwalifikacje
        f.write("\n### WpÅ‚yw usuniÄ™cia sÄ™dziego na kwalifikacje do kolejnych rund:\n\n")
        qualification_impact = analyzer.analyze_qualification_after_judge_removal()
        
        if not qualification_impact.empty:
            f.write("Analiza pokazuje, jak usuniÄ™cie poszczegÃ³lnych sÄ™dziÃ³w wpÅ‚ynÄ™Å‚oby na kwalifikacjÄ™ uczestnikÃ³w do kolejnych etapÃ³w:\n\n")
            
            # ZnajdÅº sÄ™dziÃ³w ktÃ³rzy majÄ… najwiÄ™kszy wpÅ‚yw na kwalifikacje
            for _, row in qualification_impact.iterrows():
                judge = row['judge_removed']
                
                # Stage1 -> Stage2
                lost_s1 = row.get('stage1_to_stage2', {}).get('lost_qualification', [])
                gained_s1 = row.get('stage1_to_stage2', {}).get('gained_qualification', [])
                
                # Stage2 -> Stage3
                lost_s2 = row.get('stage2_to_stage3', {}).get('lost_qualification', [])
                gained_s2 = row.get('stage2_to_stage3', {}).get('gained_qualification', [])
                
                # Stage3 -> Final
                lost_s3 = row.get('stage3_to_final', {}).get('lost_qualification', [])
                gained_s3 = row.get('stage3_to_final', {}).get('gained_qualification', [])
                
                total_changes = len(lost_s1) + len(gained_s1) + len(lost_s2) + len(gained_s2) + len(lost_s3) + len(gained_s3)
                
                if total_changes > 0:
                    f.write(f"**{judge}**:\n")
                    if lost_s1 or gained_s1:
                        f.write(f"  - Stage1â†’Stage2: {len(gained_s1)} nowych, {len(lost_s1)} odpadÅ‚oby\n")
                    if lost_s2 or gained_s2:
                        f.write(f"  - Stage2â†’Stage3: {len(gained_s2)} nowych, {len(lost_s2)} odpadÅ‚oby\n")
                    if lost_s3 or gained_s3:
                        f.write(f"  - Stage3â†’FinaÅ‚: {len(gained_s3)} nowych, {len(lost_s3)} odpadÅ‚oby\n")
        
        # 5.2 NOWA SEKCJA - Finalne wyniki bez sÄ™dziÃ³w
        f.write("\n### WpÅ‚yw usuniÄ™cia sÄ™dziego na finalne wyniki:\n\n")
        results_after_removal = analyzer.generate_results_after_judge_removal()
        
        if not results_after_removal.empty:
            f.write("Symulacja peÅ‚nych zawodÃ³w (od Stage1 do FinaÅ‚u) bez poszczegÃ³lnych sÄ™dziÃ³w pokazuje:\n\n")
            
            # ZnajdÅº najwiÄ™ksze zmiany
            rank_change_cols = [col for col in results_after_removal.columns if col.endswith('_change')]
            
            if rank_change_cols:
                # Dla kaÅ¼dego finalisty sprawdÅº najwiÄ™ksze wahania
                top_finalists = results_after_removal.head(10)
                
                f.write("**TOP 10 finalistÃ³w - stabilnoÅ›Ä‡ pozycji:**\n\n")
                for _, row in top_finalists.iterrows():
                    name = f"{row['imiÄ™']} {row['nazwisko']}"
                    orig_rank = row['original_rank']
                    
                    # ZnajdÅº najwiÄ™kszÄ… zmianÄ™ dla tego uczestnika
                    changes = []
                    for col in rank_change_cols:
                        if row[col] != 'n/a' and row[col] != 'error':
                            changes.append(abs(int(row[col])))
                    
                    if changes:
                        max_change = max(changes)
                        avg_change = np.mean(changes)
                        f.write(f"- **Miejsce {orig_rank}: {name}** - max wahanie: Â±{max_change}, Å›rednie: Â±{avg_change:.1f}\n")
        
        # 6. Faworyci
        f.write("\n## 5. Analiza faworyzowania\n\n")
        favorites = analyzer.find_judge_favorites(min_stages=3)
        
        if not favorites.empty:
            # Najsilniejsze przypadki faworyzowania
            top_fav = favorites[favorites['type'] == 'favorite'].nlargest(3, 'avg_difference')
            if not top_fav.empty:
                f.write("### Najsilniejsze przypadki faworyzowania:\n")
                for _, row in top_fav.iterrows():
                    f.write(f"- **{row['judge']}** â†’ {row['participant_name']}: +{row['avg_difference']:.2f} punkta Å›rednio\n")
            
            # Najsilniejsze przypadki niedoceniania
            top_unfav = favorites[favorites['type'] == 'unfavorite'].nsmallest(3, 'avg_difference')
            if not top_unfav.empty:
                f.write("\n### Najsilniejsze przypadki niedoceniania:\n")
                for _, row in top_unfav.iterrows():
                    f.write(f"- **{row['judge']}** â†’ {row['participant_name']}: {row['avg_difference']:.2f} punkta Å›rednio\n")
        
        # 7. Wyniki finalne
        f.write("\n## 6. Wyniki koÅ„cowe\n\n")
        if 'final_cumulative' in processor.cumulative_scores:
            final_results = processor.cumulative_scores['final_cumulative']
            f.write("### TOP 10 finalistÃ³w:\n")
            for _, row in final_results.head(10).iterrows():
                f.write(f"{int(row['rank'])}. **{row['imiÄ™']} {row['nazwisko']}** - {row['cumulative_score']:.2f} punktÃ³w\n")
        
        # 8. Wnioski
        f.write("\n## 7. Kluczowe wnioski\n\n")
        
        # SprawdÅº czy system byÅ‚ uÅ¼ywany rÃ³wnomiernie
        if not scale_usage.empty:
            avg_coverage = scale_usage['scale_coverage'].mean()
            f.write(f"- **Wykorzystanie skali**: Åšrednio sÄ™dziowie uÅ¼ywali {avg_coverage:.1f}% dostÄ™pnej skali (1-25)\n")
            
            if avg_coverage < 50:
                f.write("  - âš ï¸ Niska dywersyfikacja ocen - sÄ™dziowie uÅ¼ywajÄ… ograniczonego zakresu punktacji\n")
        
        # SprawdÅº zgodnoÅ›Ä‡ sÄ™dziÃ³w
        if not tendencies.empty:
            avg_consensus = tendencies['consensus_correlation'].mean()
            f.write(f"- **ZgodnoÅ›Ä‡ oceniania**: Åšrednia korelacja z konsensusem wynosi {avg_consensus:.3f}\n")
            
            if avg_consensus < 0.7:
                f.write("  - âš ï¸ ZnaczÄ…ce rÃ³Å¼nice w kryteriach oceniania miÄ™dzy sÄ™dziami\n")
        
        # SprawdÅº wpÅ‚yw pojedynczych sÄ™dziÃ³w
        if not removal_impact.empty:
            max_impact = removal_impact['avg_rank_change'].max()
            if max_impact > 2:
                f.write(f"- **WpÅ‚yw pojedynczych sÄ™dziÃ³w**: Maksymalny wpÅ‚yw na ranking to {max_impact:.2f} pozycji\n")
                f.write("  - âš ï¸ NiektÃ³rzy sÄ™dziowie majÄ… nieproporcjonalnie duÅ¼y wpÅ‚yw na wyniki\n")
        
        f.write("\n---\n")
        f.write("*Raport wygenerowany automatycznie*\n")
    
    print(f"Raport tekstowy zapisany w: {report_path}")


def main():
    """
    GÅ‚Ã³wna funkcja uruchamiajÄ…ca kompletnÄ… analizÄ™
    ROZSZERZONA WERSJA - zawiera nowe analizy statystyczne
    """
    print("=" * 60)
    print("ANALIZA KONKURSU CHOPINOWSKIEGO 2025")
    print("Wersja rozszerzona z analizami statystycznymi")
    print("=" * 60)
    
    # SprawdÅº czy pliki istniejÄ…
    required_files = [
        'chopin_2025_stage1_by_judge.csv',
        'chopin_2025_stage2_by_judge.csv',
        'chopin_2025_stage3_by_judge.csv',
        'chopin_2025_final_by_judge.csv'
    ]
    
    missing_files = [f for f in required_files if not os.path.exists(f)]
    if missing_files:
        print("\nâš ï¸ BrakujÄ…ce pliki:")
        for f in missing_files:
            print(f"  - {f}")
        print("\nUpewnij siÄ™, Å¼e wszystkie pliki CSV znajdujÄ… siÄ™ w bieÅ¼Ä…cym katalogu.")
        return
    
    # 1. Przetworzenie podstawowych danych
    print("\n[1/8] Wczytywanie i przetwarzanie danych...")
    processor = process_competition_data(
        'chopin_2025_stage1_by_judge.csv',
        'chopin_2025_stage2_by_judge.csv',
        'chopin_2025_stage3_by_judge.csv',
        'chopin_2025_final_by_judge.csv',
        output_dir='results'
    )
    
    # 2. Zaawansowane analizy
    print("\n[2/8] Przeprowadzanie zaawansowanych analiz...")
    analyzer = run_advanced_analysis(processor, output_dir='advanced_results')
    
    # 3. Wizualizacje podstawowe
    print("\n[3/8] Generowanie wizualizacji podstawowych...")
    visualizer = ChopinVisualization(processor, analyzer)
    visualizer.create_comprehensive_report(output_dir='visualizations')
    
    # 4. NOWE - Analiza zrÃ³Å¼nicowania ocen
    print("\n[4/8] Analiza zrÃ³Å¼nicowania ocen uczestnikÃ³w...")
    controversy_analyzer = run_controversy_analysis(processor, output_dir='score_diversity_results')
    
    # 5. NOWE - Analizy statystyczne
    print("\n[5/8] Zaawansowane analizy statystyczne...")
    statistical_analyzer = run_statistical_analysis(processor, output_dir='statistical_results')
    
    # 6. NOWE - Clustering i PCA
    print("\n[6/8] Analiza clusteringu i PCA...")
    clustering_analyzer = run_clustering_analysis(processor, output_dir='clustering_results')
    
    # 7. NOWE - Wizualizacje statystyczne
    print("\n[7/8] Generowanie wizualizacji statystycznych...")
    stat_visualizer = ChopinStatisticalVisualization(
        processor, 
        controversy_analyzer=controversy_analyzer,
        statistical_analyzer=statistical_analyzer,
        clustering_analyzer=clustering_analyzer
    )
    stat_visualizer.create_comprehensive_statistical_report(output_dir='visualizations')

    analyzer = run_multistage_analysis(data_files, output_dir='multistage_results')
    run_advanced_visualizations(clustering_analyzer, output_dir='visualizations')
    
    # 8. Raport tekstowy (POPRAWIONY)
    print("\n[8/8] Generowanie raportu tekstowego...")
    create_analysis_report(processor, analyzer, visualizer, output_dir='full_analysis')
    
    # 9. Podsumowanie
    print("\n" + "=" * 60)
    print("STRUKTURA WYNIKÃ“W:")
    print("=" * 60)
    print("ğŸ“ results/                      - Podstawowe wyniki i skorygowane oceny")
    print("ğŸ“ advanced_results/             - Zaawansowane analizy sÄ™dziÃ³w")
    print("ğŸ“ score_diversity_results/      - Analiza zrÃ³Å¼nicowania ocen uczestnikÃ³w")
    print("ğŸ“ statistical_results/          - Analizy statystyczne (CI, significance)")
    print("ğŸ“ clustering_results/           - Clustering i PCA")
    print("ğŸ“ visualizations/               - Wykresy podstawowe")
    print("ğŸ“ statistical_visualizations/   - Wykresy statystyczne")
    print("ğŸ“ full_analysis/                - Kompletny raport tekstowy")
    
    print("\nğŸ“Š Kluczowe pliki:")
    print("  - results/final_cumulative.csv                      - KoÅ„cowy ranking")
    print("  - advanced_results/judge_tendencies.csv             - Tendencje sÄ™dziÃ³w")
    print("  - score_diversity_results/most_diverse_scores.csv   - Najbardziej zrÃ³Å¼nicowane oceny")
    print("  - statistical_results/bootstrap_ci_final.csv        - Confidence intervals")
    print("  - statistical_results/significance_final.csv        - IstotnoÅ›Ä‡ statystyczna")
    print("  - statistical_results/kendall_tau_pairwise.csv      - ZgodnoÅ›Ä‡ sÄ™dziÃ³w")
    print("  - clustering_results/kmeans_clusters_final.csv      - Clustering uczestnikÃ³w")
    print("  - clustering_results/judge_pca_scores.csv           - PCA sÄ™dziÃ³w")
    print("  - full_analysis/analysis_report.md                  - Raport tekstowy")
    
    print("\nâœ… Analiza zakoÅ„czona pomyÅ›lnie!")


if __name__ == "__main__":
    main()
